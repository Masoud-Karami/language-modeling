{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize inputs\n",
    "TEXT = torchtext.data.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 10k fields of the PTB data\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(\n",
    "    path=\"../data\", \n",
    "    train=\"train.txt\", validation=\"valid.txt\", test=\"valid.txt\", text_field=TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 1\n"
     ]
    }
   ],
   "source": [
    "# we train on the entire corpus, modeled as a single sentence\n",
    "print('len(train)', len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 10001\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary. 10001 because the vocab has <unk> but then torchtext adds its own\n",
    "TEXT.build_vocab(train)\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging, reduce vocabulary.\n",
    "if False:\n",
    "    TEXT.build_vocab(train, max_size=1000)\n",
    "    print(len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make batch iterators\n",
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), batch_size=10, device=-1, bptt_len=32, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of text batch [max bptt length, batch size] torch.Size([32, 10])\n",
      "Second in batch Variable containing:\n",
      "   8\n",
      " 202\n",
      "  77\n",
      "   5\n",
      " 183\n",
      " 561\n",
      "   0\n",
      "  18\n",
      " 975\n",
      " 976\n",
      "   7\n",
      " 943\n",
      "   5\n",
      " 157\n",
      "  78\n",
      "   0\n",
      " 289\n",
      " 645\n",
      "   3\n",
      "  30\n",
      " 132\n",
      "   0\n",
      "  20\n",
      "   2\n",
      " 273\n",
      "   0\n",
      "  17\n",
      "   9\n",
      " 117\n",
      "   0\n",
      " 969\n",
      "   6\n",
      "[torch.LongTensor of size 32]\n",
      "\n",
      "Converted back to string:  in part because of buy programs <unk> by stock-index arbitrage a form of program trading <unk> futures contracts <eos> but interest <unk> as the day <unk> on and investors <unk> ahead to\n"
     ]
    }
   ],
   "source": [
    "# each batch is a string of length 32 and sentences are ended with a special <eos> token\n",
    "it = iter(train_iter)\n",
    "batch = next(it) \n",
    "print(\"Size of text batch [max bptt length, batch size]\", batch.text.size())\n",
    "print(\"Second in batch\", batch.text[:, 2])\n",
    "print(\"Converted back to string: \", \" \".join([TEXT.vocab.itos[i] for i in batch.text[:, 2].data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted back to string:  the <unk> later this week of two important economic reports <eos> the first is wednesday 's <unk> of <unk> managers considered a good <unk> of how the nation 's manufacturing <unk> <unk>\n"
     ]
    }
   ],
   "source": [
    "# each consecutive batch is a continuation of the previous one. there are no separate labels\n",
    "batch = next(it)\n",
    "print(\"Converted back to string: \", \" \".join([TEXT.vocab.itos[i] for i in batch.text[:, 2].data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but while the new york stock exchange did n't fall ___\r\n",
      "some circuit breakers installed after the october N crash failed ___\r\n",
      "the N stock specialist firms on the big board floor ___\r\n",
      "big investment banks refused to step up to the plate ___\r\n",
      "heavy selling of standard & poor 's 500-stock index futures ___\r\n",
      "seven big board stocks ual amr bankamerica walt disney capital ___\r\n",
      "once again the specialists were not able to handle the ___\r\n",
      "<unk> james <unk> chairman of specialists henderson brothers inc. it ___\r\n",
      "when the dollar is in a <unk> even central banks ___\r\n",
      "speculators are calling for a degree of liquidity that is ___\r\n"
     ]
    }
   ],
   "source": [
    "# the task is such that given a 10 word prefix of sentences, \n",
    "# we predict 10 possible next word candidates\n",
    "!head input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sob/Desktop/cs287/homeworks/env/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: generator 'BPTTIterator.__iter__' raised StopIteration\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# as a sample Kaggle submission, let's build a majority-baseline (naive unigram model)\n",
    "from collections import Counter\n",
    "count = Counter()\n",
    "for batch in iter(train_iter):\n",
    "    count.update(batch.text.view(-1).data.tolist())\n",
    "count[TEXT.vocab.stoi[\"<eos>\"]] = 0\n",
    "predictions = [TEXT.vocab.itos[i] for i, c in count.most_common(20)]\n",
    "with open(\"sample.txt\", \"w\") as fout: \n",
    "    print(\"id,word\", file=fout)\n",
    "    for i, l in enumerate(open(\"input.txt\"), 1):\n",
    "        print(\"%d,%s\"%(i, \" \".join(predictions)), file=fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
